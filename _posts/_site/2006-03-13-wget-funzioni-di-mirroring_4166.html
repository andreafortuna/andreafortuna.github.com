<p>Chi non conosce Wget, l'utility GNU per il download di file?</p><p>Oltre&nbsp;alle opzioni di default, per scaricare un singolo file da un server (ftp o web), come <em>wget </em><a href="http://indirizzo/file.zip"><em>http://indirizzo/file.zip</em></a><em>&nbsp;</em>esistono altre funzionalita' molto utili.</p><a name='more'></a><p>E' possibile ad esempio scaricare una pagina in maniera <em>ricorsiva</em>, effettuando il download della pagina e dei link ad essa associati:</p><p>wget -r <a href="http://oldsite.andreafortuna.net/">http://oldsite.andreafortuna.net</a></p><p>In questo caso, senza specificare la <em>profondita' </em>di download, verra' usato il livello di default, corrispondente a 5: in pratica verranno seguiti i 5 links successivi alla pagina da scaricare.</p><p>Altre opzioni utili:</p><p>-b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;esegue wget in background <br />-l&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; specifica il livello di ricorsione (il default e'&nbsp;5) <br />-c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fa il resume di un download precedentemente interrotto<br />-c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; legge una lista di url da scaricare&nbsp;da un file specificato <br />-convert-link&nbsp;&nbsp;&nbsp;&nbsp; converte il link da assoluti a relativi per visualizzare la pagina offline <br />-mirror&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ricontrolla un sito gia' scaricato ed esegue un aggiornamento dei file modificati<br />-nq&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; evita di scaricare link che fanno riferimento ad altri siti </p><p>...ed alcuni esempi:</p><blockquote><p><br />wget -r -c -l 3 -o operazioni.log&nbsp;<a href="http://oldsite.andreafortuna.net/">oldsite.andreafortuna.net</a> </p></blockquote><p>scarica l'index e i relativi link con un livello di profondit&agrave; pari a 3; il log dell'operazione&nbsp;viene scritto nel file operazioni.log </p><blockquote><p>wget -mirror&nbsp;<a href="http://oldsite.andreafortuna.net/">oldsite.andreafortuna.net</a> </p></blockquote><p>Fa la copia speculare del sito: aggiorna il download effettuato in precedenza scaricando solo i file aggiornati.</p><p>Wget e' molto conosciuto e utilizzato su <a href="http://www.gnu.org/software/wget/wget.html" target="_blank">Linux</a>, ma ne esiste un porting ben realizzato anche per <a href="http://gnuwin32.sourceforge.net/packages/wget.htm" target="_blank">Windows</a>.</p>